[{"title":"The AI that scored 95% — until consultants learned it was AI","link":"https://venturebeat.com/ai/the-ai-that-scored-95-until-consultants-learned-it-was-ai","pubDate":"Wed, 10 Dec 2025 15:00:00 GMT","enclosure":{"url":"https://images.ctfassets.net/jdtwqhzvc2n1/7IoiYyTs0K9D4WfYDzJvhy/2cd15991676cc0648bffb25178642417/AdobeStock_571280209_Preview.jpeg?w=300&q=30","length":"0","type":"image/jpeg"},"content":"<p><i>Presented by SAP</i></p><hr/><p>When SAP ran a quiet internal experiment to gauge consultant attitudes toward AI, the results were striking. Five teams were asked to validate answers to more than 1,000 business requirements completed by SAP’s AI co-pilot, Joule for Consultants — a workload that would normally take several weeks.</p><p>Four teams were told the analysis had been completed by junior interns fresh out of school. They reviewed the material, found it impressive, and rated the work about 95% accurate.</p><p>The fifth team was told the very same answers had come from AI.</p><p>They rejected almost everything.</p><p>Only when asked to validate each answer one by one did they discover that the AI was, in fact, highly accurate — surfacing detailed insights the consultants had initially dismissed. The overall accuracy? Again, about 95%.</p><p>“The lesson learned here is that we need to be very cautious as we introduce AI — especially in how we communicate with senior consultants about its possibilities and how to integrate it into their workflows,” says Guillermo B. Vazquez Mendez, chief architect, RI business transformation and architecture, SAP America Inc.</p><p>The experiment has since become a revealing starting point for SAP’s push toward the consultant of 2030: a practitioner who is deeply human, enabled by AI, and no longer weighed down by the technical grunt work of the past.</p><h3>Overcoming AI skepticism</h3><p>Resistance isn’t surprising, Vazquez notes. Consultants with two or three decades of experience carry enormous institutional knowledge — and an understandable degree of caution.</p><p>But AI copilots like Joule for Consultants are not replacing expertise. They’re amplifying it.</p><p>“What Joule really does is make their very expensive time far more effective,” Vazquez says. “It removes the clerical work, so they can focus on turning out high-quality answers in a fraction of the time.”</p><p>He emphasizes this message constantly: “AI is not replacing you. It’s a tool for you. Human oversight is always required. But now, instead of spending your time looking for documentation, you’re gaining significant time and boosting the effectiveness and detail of your answers.”</p><h3>The consultant time-shift: from tech execution to business insight</h3><p>Historically, consultants spent about 80% of their time understanding technical systems — how processes run, how data flows, how functions execute. Customers, by contrast, spend 80% of their time focused on their business.</p><p>That mismatch is exactly where Joule steps in.</p><p>“There’s a gap there — and the bridge is AI,” Vazquez says. “It flips the time equation, enabling consultants to invest more of their energy in understanding the customer’s industry and business goals. AI takes on the heavy technical lift, so consultants can focus on driving the right business outcomes.”</p><h3>Bringing new consultants up to speed</h3><p>AI is also transforming how new hires learn.</p><p>“We’re excited to see Joule acting as a bridge between senior consultants, who are adapting more slowly, and interns and new consultants who are already technically savvy,” Vazquez says.</p><p>Junior consultants ramp up faster because Joule helps them operate independently. Seniors, meanwhile, engage where their insight matters most.</p><p>This is also where many consultants learn the fundamentals of today’s AI copilots. Much of the work depends on prompt engineering — for instance, instructing Joule to act as a senior chief technology architect specializing in finance and SAP S/4HANA 2023, then asking it to analyze business requirements and deliver the output as tables or PowerPoint slides.</p><p>Once they grasp how to frame prompts, consultants consistently get higher-quality, more structured answers.</p><p>New architects are also able to communicate more clearly with their more experienced counterparts. They know what they don’t know and can ask targeted questions, which makes mentorship far smoother. It’s created a real synergy, Vazquez adds — senior consultants see how quickly new hires are adapting and learning with AI, and that momentum encourages them to keep pace and adopt the technology themselves.</p><h3>Looking ahead to the future of AI copilots</h3><p>“We’re still in the baby steps of AI — we’re toddlers,” Vazquez says. “Right now, copilots depend on prompt engineering to get good answers. The better you prompt, the better the answer you get.”</p><p>But that represents only the earliest phase of what these systems will eventually do. As copilots mature, they’ll move beyond responding to prompts and start interpreting entire business processes — understanding the sequence of steps, identifying where human intervention is needed, and spotting where an AI agent could take over. That shift is what leads directly into agentic AI.</p><p>SAP’s depth of process knowledge is what makes that evolution possible. The company has mapped more than 3,500 business processes across industries — a repository Vazquez calls “some of the most valuable, rigorously tested processes developed in the last 50 years.” Every day, SAP systems support roughly $7.3 trillion in global commerce, giving these emerging AI agents a rich foundation to navigate and reason over.</p><p>“With that level of process insight and data, we can take a real leap forward,” he says, “equipping our consultants with agentic AI that can solve complex challenges and push us toward increasingly autonomous systems.”</p><hr/><p>\n<i>Sponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact </i><a href=\"mailto:sales@venturebeat.com\"><i><u>sales@venturebeat.com</u></i></a><i>.</i></p>","contentSnippet":"Presented by SAP\n\nWhen SAP ran a quiet internal experiment to gauge consultant attitudes toward AI, the results were striking. Five teams were asked to validate answers to more than 1,000 business requirements completed by SAP’s AI co-pilot, Joule for Consultants — a workload that would normally take several weeks.\nFour teams were told the analysis had been completed by junior interns fresh out of school. They reviewed the material, found it impressive, and rated the work about 95% accurate.\nThe fifth team was told the very same answers had come from AI.\nThey rejected almost everything.\nOnly when asked to validate each answer one by one did they discover that the AI was, in fact, highly accurate — surfacing detailed insights the consultants had initially dismissed. The overall accuracy? Again, about 95%.\n“The lesson learned here is that we need to be very cautious as we introduce AI — especially in how we communicate with senior consultants about its possibilities and how to integrate it into their workflows,” says Guillermo B. Vazquez Mendez, chief architect, RI business transformation and architecture, SAP America Inc.\nThe experiment has since become a revealing starting point for SAP’s push toward the consultant of 2030: a practitioner who is deeply human, enabled by AI, and no longer weighed down by the technical grunt work of the past.\nOvercoming AI skepticism\nResistance isn’t surprising, Vazquez notes. Consultants with two or three decades of experience carry enormous institutional knowledge — and an understandable degree of caution.\nBut AI copilots like Joule for Consultants are not replacing expertise. They’re amplifying it.\n“What Joule really does is make their very expensive time far more effective,” Vazquez says. “It removes the clerical work, so they can focus on turning out high-quality answers in a fraction of the time.”\nHe emphasizes this message constantly: “AI is not replacing you. It’s a tool for you. Human oversight is always required. But now, instead of spending your time looking for documentation, you’re gaining significant time and boosting the effectiveness and detail of your answers.”\nThe consultant time-shift: from tech execution to business insight\nHistorically, consultants spent about 80% of their time understanding technical systems — how processes run, how data flows, how functions execute. Customers, by contrast, spend 80% of their time focused on their business.\nThat mismatch is exactly where Joule steps in.\n“There’s a gap there — and the bridge is AI,” Vazquez says. “It flips the time equation, enabling consultants to invest more of their energy in understanding the customer’s industry and business goals. AI takes on the heavy technical lift, so consultants can focus on driving the right business outcomes.”\nBringing new consultants up to speed\nAI is also transforming how new hires learn.\n“We’re excited to see Joule acting as a bridge between senior consultants, who are adapting more slowly, and interns and new consultants who are already technically savvy,” Vazquez says.\nJunior consultants ramp up faster because Joule helps them operate independently. Seniors, meanwhile, engage where their insight matters most.\nThis is also where many consultants learn the fundamentals of today’s AI copilots. Much of the work depends on prompt engineering — for instance, instructing Joule to act as a senior chief technology architect specializing in finance and SAP S/4HANA 2023, then asking it to analyze business requirements and deliver the output as tables or PowerPoint slides.\nOnce they grasp how to frame prompts, consultants consistently get higher-quality, more structured answers.\nNew architects are also able to communicate more clearly with their more experienced counterparts. They know what they don’t know and can ask targeted questions, which makes mentorship far smoother. It’s created a real synergy, Vazquez adds — senior consultants see how quickly new hires are adapting and learning with AI, and that momentum encourages them to keep pace and adopt the technology themselves.\nLooking ahead to the future of AI copilots\n“We’re still in the baby steps of AI — we’re toddlers,” Vazquez says. “Right now, copilots depend on prompt engineering to get good answers. The better you prompt, the better the answer you get.”\nBut that represents only the earliest phase of what these systems will eventually do. As copilots mature, they’ll move beyond responding to prompts and start interpreting entire business processes — understanding the sequence of steps, identifying where human intervention is needed, and spotting where an AI agent could take over. That shift is what leads directly into agentic AI.\nSAP’s depth of process knowledge is what makes that evolution possible. The company has mapped more than 3,500 business processes across industries — a repository Vazquez calls “some of the most valuable, rigorously tested processes developed in the last 50 years.” Every day, SAP systems support roughly $7.3 trillion in global commerce, giving these emerging AI agents a rich foundation to navigate and reason over.\n“With that level of process insight and data, we can take a real leap forward,” he says, “equipping our consultants with agentic AI that can solve complex challenges and push us toward increasingly autonomous systems.”\n\nSponsored articles are content produced by a company that is either paying for the post or has a business relationship with VentureBeat, and they’re always clearly marked. For more information, contact sales@venturebeat.com.","guid":"FNaGhLArww10Oem1tqKYg","categories":["AI"],"isoDate":"2025-12-10T15:00:00.000Z"},{"creator":"Javier Marquez","title":"Un anillo que no necesita la nube y no se carga: Pebble quiere que llevemos una “memoria externa” para el cerebro en el dedo ","link":"https://www.xataka.com/wearables/anillo-que-no-necesita-nube-no-se-carga-pebble-quiere-que-llevemos-memoria-externa-para-cerebro-dedo","pubDate":"Tue, 09 Dec 2025 21:30:13 +0100","dc:creator":"Javier Marquez","content":"\n     \n                                             <p>\n      <img src=\"https://i.blogs.es/9122e3/meet-pebble-index-01-external-memory-for-your-brain-0-blackhero/1024_2000.jpeg\" alt=\"Un&#x20;anillo&#x20;que&#x20;no&#x20;necesita&#x20;la&#x20;nube&#x20;y&#x20;no&#x20;se&#x20;carga&#x3A;&#x20;Pebble&#x20;quiere&#x20;que&#x20;llevemos&#x20;una&#x20;&#x201C;memoria&#x20;externa&#x201D;&#x20;para&#x20;el&#x20;cerebro&#x20;en&#x20;el&#x20;dedo&#x20;\">\n    </p>\n    <p>Hay momentos cotidianos en los que se nos cruza una idea fugaz y sabemos que, si no la guardamos al instante, probablemente desaparecerá sin dejar rastro. Puede ocurrir mientras vamos en bici, cocinamos o simplemente caminamos con las manos ocupadas, cuando sacar el móvil resulta poco cómodo o directamente imposible. Esa sensación de perder algo que parecía importante ha llevado a algunas empresas a explorar una solución inesperada, convertir el dedo índice en un lugar donde capturar pensamientos rápidos antes de que se escapen.</p>\n<!-- BREAK 1 --><p><strong>El miedo a olvidar lo importante.</strong> Para Pebble, el desafío no está solo en tener una idea fuera de momento, sino en la frecuencia con la que ocurre. <a rel=\"noopener, noreferrer\" href=\"https://repebble.com/index#:~:text=Do%20you%20ever%20have%20flashes%20of%20insight%20or%20an%20idea%20worth%20remembering%3F%20This%20happens%20to%20me%205%2D10%20times%20every%20day.%20If%20I%20don%27t%20write%20down%20the%20thought%20immediately%2C%20it%20slips%20out%20of%20my%20mind.\">Su fundador afirma</a> que a él le sucede entre cinco y diez veces al día, y que lo más frustrante no es la idea en sí, sino la certeza posterior de haber olvidado algo sin poder recuperarlo. Esa sensación recurrente es la que, según la compañía, justifica buscar un mecanismo más directo para registrar pensamientos breves antes de que se pierda su contexto.</p>\n<p><strong>Un anillo bloc de notas.</strong> El dispositivo que propone Pebble, el <a rel=\"noopener, noreferrer\" href=\"https://repebble.com/index\">Index 01</a>, adopta la forma de un anillo compacto, construido en acero inoxidable y equipado con un botón físico y un micrófono. Al presionarlo, el usuario puede capturar una nota corta de voz de manera inmediata. Está disponible en varios colores y tamaños, y cuenta con resistencia al agua para soportar un uso continuado. Su función principal es ofrecer un punto de entrada rápido para guardar información sin depender del teléfono en el momento exacto en que surge.</p>\n<!-- BREAK 2 --><p><strong>Del dedo a la app:</strong> Cada grabación empieza con una pulsación del botón, que activa el micrófono del anillo y guarda el audio en su memoria interna, sin ningún procesamiento adicional. Cuando el móvil está cerca, la grabación se transfiere por Bluetooth y es allí donde ocurre todo el trabajo: la aplicación de Pebble convierte la voz en texto mediante un modelo de reconocimiento que funciona en local y, después, un LLM que también se ejecuta en el propio teléfono determina si debe crear una nota, programar un recordatorio o añadir un evento al calendario.</p>\n\r<div class=\"article-asset-video article-asset-normal\">\n <div class=\"asset-content\">\n  <div class=\"base-asset-video\">\n   <div class=\"js-dailymotion\">\n    <script type=\"application/json\">\n                          {\"videoId\":\"x8rvypw\",\"autoplay\":false,\"title\":\"ANILLO INTELIGENTE: ¿SUSTITUYE A MI SMARTWATCH?\", \"tag\":\"webedia-prod\", \"duration\":\"561\"}\n                  </script>\n   </div>\n  </div>\n </div>\n</div>\n<p><strong>Nunca se enchufa, pero se agota:</strong> Pebble opta por una batería de óxido de plata similar a la que usan los audífonos, lo que permite que el anillo funcione durante años sin necesidad de recargarlo. Según la compañía, un uso medio de entre diez y veinte grabaciones diarias de pocos segundos equivale a unas doce o quince horas de audio acumulado, suficiente para alcanzar esa autonomía prolongada. Cuando la pila se acerca al final, la aplicación avisa al usuario, que puede comprar otro anillo y enviar el anterior para su reciclaje.</p>\n<!-- BREAK 3 --><p>El planteamiento implica que la batería no puede sustituirse ni recargarse, algo que Pebble reconoce abiertamente. Cuando llega el aviso de fin de vida útil, el usuario debe adquirir un anillo nuevo. Como decimos, la compañía ofrece la posibilidad de enviar el dispositivo antiguo para su reciclaje, pero no menciona descuentos, programas de reposición ni compensaciones por devolución, por lo que el reemplazo aparentemente funciona como una compra independiente.</p>\n\r<div class=\"article-asset-image article-asset-normal article-asset-center\">\n <div class=\"asset-content\">\n                   \n   <img alt=\"Meet Pebble Index 01 External Memory For Your Brain 1 2c146dc6 62c0 4079 8f46 56413e3f5ae9\" class=\"centro_sinmarco\" src=\"https://i.blogs.es/45dc00/meet-pebble-index-01-external-memory-for-your-brain-1-2c146dc6-62c0-4079-8f46-56413e3f5ae9/450_1000.jpeg\">\n   \n      </div>\n</div>\n<p>Pebble insiste en que el anillo está concebido para procesar la información de forma local y limitar su alcance a lo estrictamente necesario. La conexión entre el dispositivo y el móvil va cifrada, y tanto la conversión de voz a texto como la clasificación mediante un modelo de lenguaje ocurren en el propio teléfono y, por defecto, no requieren enviar los datos a servidores externos, aunque la compañía ofrece un sistema opcional de copia de seguridad en la nube para las grabaciones que aún está en desarrollo y que planea ofrecer cifrado. El anillo no escucha de manera continua ni registra datos de salud, y tampoco integra altavoz ni vibración. Su funcionamiento se limita al momento en que el usuario mantiene pulsado el botón.</p>\n<!-- BREAK 4 -->\r<div class=\"article-asset-image article-asset-normal article-asset-center\">\n <div class=\"asset-content\">\n                   \n   <img alt=\"Meet Pebble Index 01 External Memory For Your Brain 3 995889e9 Cbc4 4225 985a 17ec4aa5a9ee\" class=\"centro_sinmarco\" src=\"https://i.blogs.es/e36d40/meet-pebble-index-01-external-memory-for-your-brain-3-995889e9-cbc4-4225-985a-17ec4aa5a9ee/450_1000.jpeg\">\n   \n      </div>\n</div>\n<p><strong>Cuando la memoria se deja hackear.</strong> Más allá de registrar notas, Pebble permite configurar el anillo para realizar acciones adicionales mediante pulsaciones simples o dobles, desde controlar la música hasta disparar una foto o activar rutinas de domótica. La aplicación admite enviar recordatorios a servicios como Notion y ofrece compatibilidad con más de 99 idiomas. La compañía describe además un sistema de acciones basado en MCP, unas pequeñas extensiones que se ejecutan en el propio móvil y que, según su hoja de ruta, deberían ampliar lo que el dispositivo puede hacer sin depender de un servidor central.</p>\n<!-- BREAK 5 -->\r<div class=\"article-asset-image article-asset-normal article-asset-center\">\n <div class=\"asset-content\">\n                   \n   <img alt=\"Meet Pebble Index 01 External Memory For Your Brain 5 Cf74d4f3b974212601f09fcf5109a989\" class=\"centro_sinmarco\" src=\"https://i.blogs.es/14fb78/meet-pebble-index-01-external-memory-for-your-brain-5-cf74d4f3b974212601f09fcf5109a989/450_1000.jpeg\">\n   \n      </div>\n</div>\n<p><strong>Del reloj al anillo:</strong> Pebble atraviesa una fase de relanzamiento en la que busca ampliar su catálogo más allá del smartwatch. Tras recuperar su marca y enviar sus nuevos <a rel=\"noopener, noreferrer\" href=\"https://repebble.com/watch\">Pebble 2 Duo</a>, prepara la llegada de <a rel=\"noopener, noreferrer\" href=\"https://repebble.com/watch\">Pebble 2 Time</a> con un nivel significativo de demanda previa. En ese escenario aparece Index 01. <a rel=\"noopener, noreferrer\" href=\"https://repebble.com/index#:~:text=External%20Memory%20For%20Your%20Brain,-Catch%20your%20best\">El propio fundador resume</a> su apuesta afirmando que el anillo ha dejado de ser un dispositivo tecnológico para convertirse en “una extensión del cerebro”, una frase que refleja la ambición con la que la compañía presenta este proyecto.</p>\n<!-- BREAK 6 -->\r<div class=\"article-asset article-asset-normal article-asset-center\">\n <div class=\"desvio-container\">\n  <div class=\"desvio\">\n   <div class=\"desvio-figure js-desvio-figure\">\n    <a href=\"https://www.xataka.com/wearables/nueva-pebble-recordatorio-para-industria-tecnologica-hay-grandeza-ambiciones-pequenas\" class=\"pivot-outboundlink\" data-vars-post-title=\"La nueva Pebble es un recordatorio para la industria tecnológica: hay grandeza en las ambiciones pequeñas \">\n     <img alt=\"La&#x20;nueva&#x20;Pebble&#x20;es&#x20;un&#x20;recordatorio&#x20;para&#x20;la&#x20;industria&#x20;tecnol&#x00F3;gica&#x3A;&#x20;hay&#x20;grandeza&#x20;en&#x20;las&#x20;ambiciones&#x20;peque&#x00F1;as&#x20;\" width=\"375\" height=\"142\" src=\"https://i.blogs.es/3243d1/pebble/375_142.jpeg\">\n    </a>\n   </div>\n   <div class=\"desvio-summary\">\n    <div class=\"desvio-taxonomy js-desvio-taxonomy\">\n     <a href=\"https://www.xataka.com/wearables/nueva-pebble-recordatorio-para-industria-tecnologica-hay-grandeza-ambiciones-pequenas\" class=\"desvio-taxonomy-anchor pivot-outboundlink\" data-vars-post-title=\"La nueva Pebble es un recordatorio para la industria tecnológica: hay grandeza en las ambiciones pequeñas \">En Xataka</a>\n    </div>\n    <a href=\"https://www.xataka.com/wearables/nueva-pebble-recordatorio-para-industria-tecnologica-hay-grandeza-ambiciones-pequenas\" class=\"desvio-title js-desvio-title pivot-outboundlink\" data-vars-post-title=\"La nueva Pebble es un recordatorio para la industria tecnológica: hay grandeza en las ambiciones pequeñas \">La nueva Pebble es un recordatorio para la industria tecnológica: hay grandeza en las ambiciones pequeñas </a>\n   </div>\n  </div>\n </div>\n</div>\n<p><strong>Precio y disponibilidad del Index 01</strong>. La compañía sitúa el precio inicial en 75 dólares durante la preventa, con una subida a 99 dólares cuando las primeras unidades empiecen a enviarse a nivel mundial a partir de marzo de 2026. El dispositivo está en fase de validación de diseño y se produce en la misma planta que trabaja con Pebble Time 2, donde se ensamblan los prototipos actuales. Los envíos partirán desde Asia bajo un sistema DDP, de modo que los impuestos y tasas se gestionarán antes de la entrega.</p>\n<!-- BREAK 7 --><p>Imágenes | Pebble</p>\n<p>En Xataka | <a class=\"text-outboundlink\" href=\"https://www.xataka.com/realidad-virtual-aumentada/hemos-probado-nuevas-gafas-google-gemini-ia-tecnologia-hoy-impulsan-sueno-que-glass-prometia\" data-vars-post-title=\"Hemos probado las nuevas gafas de Google con Gemini: la IA y la tecnología de hoy impulsan el sueño que Glass prometía\" data-vars-post-url=\"https://www.xataka.com/realidad-virtual-aumentada/hemos-probado-nuevas-gafas-google-gemini-ia-tecnologia-hoy-impulsan-sueno-que-glass-prometia\">Hemos probado las nuevas gafas de Google con Gemini: la IA y la tecnología de hoy impulsan el sueño que Glass prometía</a></p>\n\r<script>\n (function() {\n  window._JS_MODULES = window._JS_MODULES || {};\n  var headElement = document.getElementsByTagName('head')[0];\n  if (_JS_MODULES.instagram) {\n   var instagramScript = document.createElement('script');\n   instagramScript.src = 'https://platform.instagram.com/en_US/embeds.js';\n   instagramScript.async = true;\n   instagramScript.defer = true;\n   headElement.appendChild(instagramScript);\n  }\n })();\n</script>\n\n\n                <p> - <br/> La noticia\n      <a href=\"https://www.xataka.com/wearables/anillo-que-no-necesita-nube-no-se-carga-pebble-quiere-que-llevemos-memoria-externa-para-cerebro-dedo?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=09_Dec_2025\">\n       <em> Un anillo que no necesita la nube y no se carga: Pebble quiere que llevemos una “memoria externa” para el cerebro en el dedo  </em>\n      </a>\n      fue publicada originalmente en\n      <a href=\"https://www.xataka.com?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=09_Dec_2025\">\n       <strong> Xataka </strong>\n      </a>\n             por <a\n        href=\"https://www.xataka.com/autor/javier-marquez?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=09_Dec_2025\">\n        Javier Marquez\n       </a>\n      . </p>\n               \n    ","contentSnippet":"Hay momentos cotidianos en los que se nos cruza una idea fugaz y sabemos que, si no la guardamos al instante, probablemente desaparecerá sin dejar rastro. Puede ocurrir mientras vamos en bici, cocinamos o simplemente caminamos con las manos ocupadas, cuando sacar el móvil resulta poco cómodo o directamente imposible. Esa sensación de perder algo que parecía importante ha llevado a algunas empresas a explorar una solución inesperada, convertir el dedo índice en un lugar donde capturar pensamientos rápidos antes de que se escapen.\nEl miedo a olvidar lo importante. Para Pebble, el desafío no está solo en tener una idea fuera de momento, sino en la frecuencia con la que ocurre. Su fundador afirma que a él le sucede entre cinco y diez veces al día, y que lo más frustrante no es la idea en sí, sino la certeza posterior de haber olvidado algo sin poder recuperarlo. Esa sensación recurrente es la que, según la compañía, justifica buscar un mecanismo más directo para registrar pensamientos breves antes de que se pierda su contexto.\nUn anillo bloc de notas. El dispositivo que propone Pebble, el Index 01, adopta la forma de un anillo compacto, construido en acero inoxidable y equipado con un botón físico y un micrófono. Al presionarlo, el usuario puede capturar una nota corta de voz de manera inmediata. Está disponible en varios colores y tamaños, y cuenta con resistencia al agua para soportar un uso continuado. Su función principal es ofrecer un punto de entrada rápido para guardar información sin depender del teléfono en el momento exacto en que surge.\nDel dedo a la app: Cada grabación empieza con una pulsación del botón, que activa el micrófono del anillo y guarda el audio en su memoria interna, sin ningún procesamiento adicional. Cuando el móvil está cerca, la grabación se transfiere por Bluetooth y es allí donde ocurre todo el trabajo: la aplicación de Pebble convierte la voz en texto mediante un modelo de reconocimiento que funciona en local y, después, un LLM que también se ejecuta en el propio teléfono determina si debe crear una nota, programar un recordatorio o añadir un evento al calendario.\n\r\nNunca se enchufa, pero se agota: Pebble opta por una batería de óxido de plata similar a la que usan los audífonos, lo que permite que el anillo funcione durante años sin necesidad de recargarlo. Según la compañía, un uso medio de entre diez y veinte grabaciones diarias de pocos segundos equivale a unas doce o quince horas de audio acumulado, suficiente para alcanzar esa autonomía prolongada. Cuando la pila se acerca al final, la aplicación avisa al usuario, que puede comprar otro anillo y enviar el anterior para su reciclaje.\nEl planteamiento implica que la batería no puede sustituirse ni recargarse, algo que Pebble reconoce abiertamente. Cuando llega el aviso de fin de vida útil, el usuario debe adquirir un anillo nuevo. Como decimos, la compañía ofrece la posibilidad de enviar el dispositivo antiguo para su reciclaje, pero no menciona descuentos, programas de reposición ni compensaciones por devolución, por lo que el reemplazo aparentemente funciona como una compra independiente.\n\r\nPebble insiste en que el anillo está concebido para procesar la información de forma local y limitar su alcance a lo estrictamente necesario. La conexión entre el dispositivo y el móvil va cifrada, y tanto la conversión de voz a texto como la clasificación mediante un modelo de lenguaje ocurren en el propio teléfono y, por defecto, no requieren enviar los datos a servidores externos, aunque la compañía ofrece un sistema opcional de copia de seguridad en la nube para las grabaciones que aún está en desarrollo y que planea ofrecer cifrado. El anillo no escucha de manera continua ni registra datos de salud, y tampoco integra altavoz ni vibración. Su funcionamiento se limita al momento en que el usuario mantiene pulsado el botón.\n\r\n \nCuando la memoria se deja hackear. Más allá de registrar notas, Pebble permite configurar el anillo para realizar acciones adicionales mediante pulsaciones simples o dobles, desde controlar la música hasta disparar una foto o activar rutinas de domótica. La aplicación admite enviar recordatorios a servicios como Notion y ofrece compatibilidad con más de 99 idiomas. La compañía describe además un sistema de acciones basado en MCP, unas pequeñas extensiones que se ejecutan en el propio móvil y que, según su hoja de ruta, deberían ampliar lo que el dispositivo puede hacer sin depender de un servidor central.\n\r\n \nDel reloj al anillo: Pebble atraviesa una fase de relanzamiento en la que busca ampliar su catálogo más allá del smartwatch. Tras recuperar su marca y enviar sus nuevos Pebble 2 Duo, prepara la llegada de Pebble 2 Time con un nivel significativo de demanda previa. En ese escenario aparece Index 01. El propio fundador resume su apuesta afirmando que el anillo ha dejado de ser un dispositivo tecnológico para convertirse en “una extensión del cerebro”, una frase que refleja la ambición con la que la compañía presenta este proyecto.\n\r\n \nEn Xataka\n    \nLa nueva Pebble es un recordatorio para la industria tecnológica: hay grandeza en las ambiciones pequeñas \n   \nPrecio y disponibilidad del Index 01. La compañía sitúa el precio inicial en 75 dólares durante la preventa, con una subida a 99 dólares cuando las primeras unidades empiecen a enviarse a nivel mundial a partir de marzo de 2026. El dispositivo está en fase de validación de diseño y se produce en la misma planta que trabaja con Pebble Time 2, donde se ensamblan los prototipos actuales. Los envíos partirán desde Asia bajo un sistema DDP, de modo que los impuestos y tasas se gestionarán antes de la entrega.\nImágenes | Pebble\nEn Xataka | Hemos probado las nuevas gafas de Google con Gemini: la IA y la tecnología de hoy impulsan el sueño que Glass prometía\n\r\n (function() {\n  window._JS_MODULES = window._JS_MODULES || {};\n  var headElement = document.getElementsByTagName('head')[0];\n  if (_JS_MODULES.instagram) {\n   var instagramScript = document.createElement('script');\n   instagramScript.src = 'https://platform.instagram.com/en_US/embeds.js';\n   instagramScript.async = true;\n   instagramScript.defer = true;\n   headElement.appendChild(instagramScript);\n  }\n })();\n\n\n\n                \n - \n La noticia\n      \n        Un anillo que no necesita la nube y no se carga: Pebble quiere que llevemos una “memoria externa” para el cerebro en el dedo  \n      \n      fue publicada originalmente en\n      \n        Xataka \n      \n             por \n        Javier Marquez\n       \n      .","guid":"https://www.xataka.com/wearables/anillo-que-no-necesita-nube-no-se-carga-pebble-quiere-que-llevemos-memoria-externa-para-cerebro-dedo","isoDate":"2025-12-09T20:30:13.000Z"},{"creator":"carl.franzen@venturebeat.com (Carl Franzen)","title":"Mistral launches powerful Devstral 2 coding model including open source, laptop-friendly version","link":"https://venturebeat.com/ai/mistral-launches-powerful-devstral-2-coding-model-including-open-source","pubDate":"Tue, 09 Dec 2025 19:44:00 GMT","author":"carl.franzen@venturebeat.com (Carl Franzen)","enclosure":{"url":"https://images.ctfassets.net/jdtwqhzvc2n1/5h08IT02qEnf15d2nC66XM/808f775396da3b120a6c20c72b759776/G-V5j_tz9IkXATIrqK6cF.png?w=300&q=30","length":"0","type":"image/png"},"content":"<p>French AI startup Mistral has weathered a rocky period of public questioning over the last year to emerge, now here in December 2025, with new, crowd-pleasing models for enterprise and indie developers.</p><p>Just days after releasing its <a href=\"https://venturebeat.com/ai/mistral-launches-mistral-3-a-family-of-open-models-designed-to-run-on\">powerful open source, general purpose Mistral 3 LLM family</a> for edge devices and local hardware, the <a href=\"https://mistral.ai/news/devstral-2-vibe-cli\"><b>company returned today to debut Devstral 2</b></a>.</p><p>The release includes a new pair of models optimized for software engineering tasks — again, with one small enough to run on a single laptop, offline and privately — alongside <b>Mistral Vibe,</b> a command-line interface (CLI) agent designed to allow developers to call the models up directly within their terminal environments. </p><p>The models are fast, lean, and open—at least in theory. But the real story lies not just in the benchmarks, but in how Mistral is packaging this capability: one model fully free, another conditionally so, and a terminal interface built to scale with either.</p><p>It’s an attempt not just to match proprietary systems like Claude and GPT-4 in performance, but to compete with them on developer experience—and to do so while holding onto the flag of open-source.</p><p>Both models are available now for free for a limited time <a href=\"https://docs.mistral.ai/models/devstral-2-25-12\">via Mistral’s API</a> and <a href=\"https://huggingface.co/collections/mistralai/devstral-2\">Hugging Face</a>. </p><p>The full Devstral 2 model is supported out-of-the-box in the community inference provider <a href=\"https://x.com/vllm_project/status/1998428798891765926?s=20\">vLLM</a> and on the open source agentic coding platform <a href=\"https://x.com/kilocode/status/1998412042357588461\">Kilo Code</a>.  </p><h2><b>A Coding Model Meant to Drive</b></h2><p>At the top of the announcement is Devstral 2, a 123-billion parameter dense transformer with a 256K-token context window, engineered specifically for agentic software development. </p><p>Mistral says the model achieves 72.2% on SWE-bench Verified, a benchmark designed to evaluate long-context software engineering tasks in real-world repositories.</p><p>The smaller sibling, Devstral Small 2, weighs in at 24B parameters, with the same long context window and a performance of 68.0% on SWE-bench. </p><p>On paper, that makes it the strongest open-weight model of its size, even outscoring many 70B-class competitors.</p><p>But the performance story isn’t just about raw percentages. Mistral is betting that efficient intelligence beats scale, and has made much of the fact that Devstral 2 is:</p><ul><li><p>5× smaller than DeepSeek V3.2</p></li><li><p>8× smaller than Kimi K2</p></li><li><p>Yet still matches or surpasses them on key software reasoning benchmarks.</p></li></ul><p>Human evaluations back this up. In side-by-side comparisons:</p><ul><li><p>Devstral 2 beat DeepSeek V3.2 in 42.8% of tasks, losing only 28.6%.</p></li><li><p>Against Claude Sonnet 4.5, it lost more often (53.1%)—a reminder that while the gap is narrowing, closed models still lead in overall preference.</p></li></ul><p>Still, for an open-weight model, these results place Devstral 2 at the frontier of what’s currently available to run and modify independently.</p><h2><b>Vibe CLI: A Terminal-Native Agent</b></h2><p>Alongside the models, Mistral released Vibe CLI, a command-line assistant that integrates directly with Devstral models. It’s not an IDE plugin or a ChatGPT-style code explainer. It’s a native interface designed for project-wide code understanding and orchestration, built to live inside the developer’s actual workflow.</p><p>Vibe brings a surprising degree of intelligence to the terminal:</p><ul><li><p>It reads your file tree and Git status to understand project scope.</p></li><li><p>It lets you reference files with @, run shell commands with !, and toggle behavior with slash commands.</p></li><li><p>It orchestrates changes across multiple files, tracks dependencies, retries failed executions, and can even refactor at architectural scale.</p></li></ul><p>Unlike most developer agents, which simulate a REPL from within a chat UI, Vibe starts with the shell and pulls intelligence in from there. It’s programmable, scriptable, and themeable. And it’s released under the Apache 2.0 license, meaning it’s truly free to use—in commercial settings, internal tools, or open-source extensions.</p><h2><b>Licensing Structure: Open-ish — With Revenue Limitations</b></h2><p>At first glance, Mistral’s licensing approach appears straightforward: the models are open-weight and publicly available. But a closer look reveals a line drawn through the middle of the release, with different rules for different users.</p><p>Devstral Small 2, the 24-billion parameter variant, is covered under a standard, enterprise- and developer-friendly <a href=\"https://huggingface.co/datasets/choosealicense/licenses/blob/main/markdown/apache-2.0.md\">Apache 2.0 license</a>. </p><p>That’s a gold standard in open-source: no revenue restrictions, no fine print, no need to check with legal. Enterprises can use it in production, embed it into products, and redistribute fine-tuned versions without asking for permission.</p><p>Devstral 2, the flagship 123B model, is released under what Mistral calls a “<a href=\"https://huggingface.co/mistralai/Devstral-2-123B-Instruct-2512/blob/main/LICENSE\">modified MIT license</a>.” That phrase sounds innocuous, but the modification introduces a critical limitation: any company making more than $20 million in monthly revenue cannot use the model at all—not even internally—without securing a separate commercial license from Mistral.</p><blockquote><p>“You are not authorized to exercise any rights under this license if the global consolidated monthly revenue of your company […] exceeds $20 million,” the license reads.</p></blockquote><p>The clause applies not only to the base model, but to derivatives, fine-tuned versions, and redistributed variants, regardless of who hosts them. In effect, it means that while the weights are “open,” their use is gated for large enterprises—unless they’re willing to engage with Mistral’s sales team or use the hosted API at metered pricing.</p><p>To draw an analogy: Apache 2.0 is like a public library—you walk in, borrow the book, and use it however you need. Mistral’s modified MIT license is more like a corporate co-working space that’s free for freelancers but charges rent once your company hits a certain size.</p><h2><b>Weighing Devstral Small 2 for Enterprise Use</b></h2><p>This division raises an obvious question for larger companies: can Devstral Small 2 with its more permissive and unrestricted Apache 2.0 licensing serve as a viable alternative for medium-to-large enterprises?</p><p>The answer depends on context. Devstral Small 2 scores 68.0% on SWE-bench, significantly ahead of many larger open models, and remains deployable on single-GPU or CPU-only setups. For teams focused on:</p><ul><li><p>internal tooling,</p></li><li><p>on-prem deployment,</p></li><li><p>low-latency edge inference,</p><p>…it offers a rare combination of legality, performance, and convenience.</p></li></ul><p>But the performance gap from Devstral 2 is real. For multi-agent setups, deep monorepo refactoring, or long-context code analysis, that 4-point benchmark delta may understate the actual experience difference.</p><p>For most enterprises, Devstral Small 2 will serve either as a low-friction way to prototype—or as a pragmatic bridge until licensing for Devstral 2 becomes feasible. It is not a drop-in replacement for the flagship, but it may be “good enough” in specific production slices, particularly when paired with Vibe CLI.</p><p>But because Devstral Small 2 can be run entirely offline — including on a single GPU machine or a sufficiently specced laptop — it unlocks a critical use case for developers and teams operating in tightly controlled environments. </p><p>Whether you’re a solo indie building tools on the go, or part of a company with strict data governance or compliance mandates, the ability to run a performant, long-context coding model without ever hitting the internet is a powerful differentiator. No cloud calls, no third-party telemetry, no risk of data leakage — just local inference with full visibility and control.</p><p>This matters in industries like finance, healthcare, defense, and advanced manufacturing, where data often cannot leave the network perimeter. But it’s just as useful for developers who prefer autonomy over vendor lock-in — or who want their tools to work the same on a plane, in the field, or inside an air-gapped lab. In a market where most top-tier code models are delivered as API-only SaaS products, Devstral Small 2 offers a rare level of portability, privacy, and ownership.</p><p>In that sense, Mistral isn’t just offering open models—they’re offering multiple paths to adoption, depending on your scale, compliance posture, and willingness to engage.</p><h2><b>Integration, Infrastructure, and Access</b></h2><p>From a technical standpoint, Mistral’s models are built for deployment. Devstral 2 requires a minimum of 4× H100-class GPUs, and is already available on build.nvidia.com. </p><p>Devstral Small 2 can run on a single GPU or CPU such as those in a standard laptop, making it accessible to solo developers and embedded teams alike.</p><p>Both models support quantized FP4 and FP8 weights, and are compatible with vLLM for scalable inference. Fine-tuning is supported out of the box.</p><p>API pricing—after the free introductory window—follows a token-based structure:</p><ul><li><p><b>Devstral 2:</b> $0.40 per million input tokens / $2.00 for output</p></li><li><p><b>Devstral Small 2:</b> $0.10 input / $0.30 output</p></li></ul><p>That pricing sits just below OpenAI’s GPT-4 Turbo, and well below Anthropic’s Claude Sonnet at comparable performance levels.</p><h2><b>Developer Reception: Ground-Level Buzz</b></h2><p>On X (formerly Twitter), developers reacted quickly with a wave of positive reception, with Hugging Face&#x27;s Head of Product <a href=\"https://x.com/victormustar/status/1998414127400923246\">Victor Mustar asking</a> if the small, Apache 2.0 licensed variant was the &quot;new local coding king,&quot; i.e., the one developers could use to run on their laptops directly and privately, without an internet connection:</p><div></div><p>Another popular AI news and rumors account, TestingCatalogNews, posted that it was &quot;SOTTA in coding,&quot; or &quot;State Of The Tiny Art&quot;</p><div></div><p>Another user, <a href=\"https://x.com/xlr8harder/status/1998458990565396505\">@xlr8harder</a>, took issue with the custom licensing terms for Devstral 2, writing &quot;calling the Devstral 2 license &#x27;modified MIT&#x27; is misleading at best. It’s a proprietary license with MIT-like attribution requirements.&quot;</p><div></div><p>While the tone was critical, it reflected some attention Mistral’s license structuring was receiving, particularly among developers familiar with open-use norms.</p><h2><b>Strategic Context: From Codestral to Devstral and Mistral 3</b></h2><p>Mistral’s steady push into software development tools didn’t start with Devstral 2—it began in May 2024 with <a href=\"https://venturebeat.com/ai/mistral-announces-codestral-its-first-programming-focused-ai-model\">Codestral</a>, the company’s first code-focused large language model. A 22-billion parameter system trained on more than 80 programming languages, Codestral was designed for use in developer environments ranging from basic autocompletions to full function generation. The model launched under a non-commercial license but still outperformed heavyweight competitors like CodeLlama 70B and Deepseek Coder 33B in early benchmarks such as HumanEval and RepoBench.</p><p>Codestral’s release marked Mistral’s first move into the competitive coding-model space, but it also established a now-familiar pattern: technically lean models with surprisingly strong results, a wide context window, and licensing choices that invited developer experimentation. Industry partners including JetBrains, LlamaIndex, and LangChain quickly began integrating the model into their workflows, citing its speed and tool compatibility as key differentiators.</p><p>One year later, the company followed up with <a href=\"https://venturebeat.com/ai/mistral-ai-launches-devstral-powerful-new-open-source-swe-agent-model-that-runs-on-laptops\">Devstral</a>, a 24B model purpose-built for “agentic” behavior—handling long-range reasoning, file navigation, and autonomous code modification. Released in partnership with All Hands AI and licensed under Apache 2.0, Devstral was notable not just for its portability (it could run on a MacBook or RTX 4090), but for its performance: it beat out several closed models on SWE-Bench Verified, a benchmark of 500 real-world GitHub issues.</p><p>Then came Mistral 3, announced in December 2025 as <a href=\"https://venturebeat.com/ai/mistral-launches-mistral-3-a-family-of-open-models-designed-to-run-on\">a portfolio of 10 open-weight models</a> targeting everything from drones and smartphones to cloud infrastructure. This suite included both high-end models like Mistral Large 3 (a MoE system with 41 active parameters and 256K context) and lightweight “Ministral” variants that could run on 4GB of VRAM. All were licensed under Apache 2.0, reinforcing Mistral’s commitment to flexible, edge-friendly deployment.</p><p>Mistral 3 positioned the company not as a direct competitor to frontier models like GPT-5 or Gemini 3, but as a developer-first platform for customized, localized AI systems. Co-founder Guillaume Lample described the vision as “distributed intelligence”—many smaller systems tuned for specific tasks and running outside centralized infrastructure. “In more than 90% of cases, a small model can do the job,” he told VentureBeat. “It doesn’t have to be a model with hundreds of billions of parameters.”</p><p>That broader strategy helps explain the significance of Devstral 2. It’s not a one-off release but a continuation of Mistral’s long-running commitment to code agents, local-first deployment, and open-weight availability—an ecosystem that began with Codestral, matured through Devstral, and scaled up with Mistral 3. Devstral 2, in this framing, is not just a model. It’s the next version of a playbook that’s been unfolding in public for over a year.</p><h2><b>Final Thoughts (For Now): A Fork in the Road</b></h2><p>With Devstral 2, Devstral Small 2, and Vibe CLI, Mistral AI has drawn a clear map for developers and companies alike. The tools are fast, capable, and thoughtfully integrated. But they also present <b>a choice</b>—not just in architecture, but in how and where you’re allowed to use them.</p><p>If you’re an individual developer, small startup, or open-source maintainer, this is one of the most powerful AI systems you can freely run today. </p><p>If you’re a Fortune 500 engineering lead, you’ll need to either talk to Mistral—or settle for the smaller model and make it work.</p><p>In a market increasingly dominated by black-box models and SaaS lock-ins, Mistral’s offer is still a breath of fresh air. Just read the fine print before you start building.</p>","contentSnippet":"French AI startup Mistral has weathered a rocky period of public questioning over the last year to emerge, now here in December 2025, with new, crowd-pleasing models for enterprise and indie developers.\nJust days after releasing its powerful open source, general purpose Mistral 3 LLM family for edge devices and local hardware, the company returned today to debut Devstral 2.\nThe release includes a new pair of models optimized for software engineering tasks — again, with one small enough to run on a single laptop, offline and privately — alongside Mistral Vibe, a command-line interface (CLI) agent designed to allow developers to call the models up directly within their terminal environments. \nThe models are fast, lean, and open—at least in theory. But the real story lies not just in the benchmarks, but in how Mistral is packaging this capability: one model fully free, another conditionally so, and a terminal interface built to scale with either.\nIt’s an attempt not just to match proprietary systems like Claude and GPT-4 in performance, but to compete with them on developer experience—and to do so while holding onto the flag of open-source.\nBoth models are available now for free for a limited time via Mistral’s API and Hugging Face. \nThe full Devstral 2 model is supported out-of-the-box in the community inference provider vLLM and on the open source agentic coding platform Kilo Code.  \nA Coding Model Meant to Drive\nAt the top of the announcement is Devstral 2, a 123-billion parameter dense transformer with a 256K-token context window, engineered specifically for agentic software development. \nMistral says the model achieves 72.2% on SWE-bench Verified, a benchmark designed to evaluate long-context software engineering tasks in real-world repositories.\nThe smaller sibling, Devstral Small 2, weighs in at 24B parameters, with the same long context window and a performance of 68.0% on SWE-bench. \nOn paper, that makes it the strongest open-weight model of its size, even outscoring many 70B-class competitors.\nBut the performance story isn’t just about raw percentages. Mistral is betting that efficient intelligence beats scale, and has made much of the fact that Devstral 2 is:\n\n5× smaller than DeepSeek V3.2\n\n8× smaller than Kimi K2\n\nYet still matches or surpasses them on key software reasoning benchmarks.\n\nHuman evaluations back this up. In side-by-side comparisons:\n\nDevstral 2 beat DeepSeek V3.2 in 42.8% of tasks, losing only 28.6%.\n\nAgainst Claude Sonnet 4.5, it lost more often (53.1%)—a reminder that while the gap is narrowing, closed models still lead in overall preference.\n\nStill, for an open-weight model, these results place Devstral 2 at the frontier of what’s currently available to run and modify independently.\nVibe CLI: A Terminal-Native Agent\nAlongside the models, Mistral released Vibe CLI, a command-line assistant that integrates directly with Devstral models. It’s not an IDE plugin or a ChatGPT-style code explainer. It’s a native interface designed for project-wide code understanding and orchestration, built to live inside the developer’s actual workflow.\nVibe brings a surprising degree of intelligence to the terminal:\n\nIt reads your file tree and Git status to understand project scope.\n\nIt lets you reference files with @, run shell commands with !, and toggle behavior with slash commands.\n\nIt orchestrates changes across multiple files, tracks dependencies, retries failed executions, and can even refactor at architectural scale.\n\nUnlike most developer agents, which simulate a REPL from within a chat UI, Vibe starts with the shell and pulls intelligence in from there. It’s programmable, scriptable, and themeable. And it’s released under the Apache 2.0 license, meaning it’s truly free to use—in commercial settings, internal tools, or open-source extensions.\nLicensing Structure: Open-ish — With Revenue Limitations\nAt first glance, Mistral’s licensing approach appears straightforward: the models are open-weight and publicly available. But a closer look reveals a line drawn through the middle of the release, with different rules for different users.\nDevstral Small 2, the 24-billion parameter variant, is covered under a standard, enterprise- and developer-friendly Apache 2.0 license. \nThat’s a gold standard in open-source: no revenue restrictions, no fine print, no need to check with legal. Enterprises can use it in production, embed it into products, and redistribute fine-tuned versions without asking for permission.\nDevstral 2, the flagship 123B model, is released under what Mistral calls a “modified MIT license.” That phrase sounds innocuous, but the modification introduces a critical limitation: any company making more than $20 million in monthly revenue cannot use the model at all—not even internally—without securing a separate commercial license from Mistral.\n\n“You are not authorized to exercise any rights under this license if the global consolidated monthly revenue of your company […] exceeds $20 million,” the license reads.\n\nThe clause applies not only to the base model, but to derivatives, fine-tuned versions, and redistributed variants, regardless of who hosts them. In effect, it means that while the weights are “open,” their use is gated for large enterprises—unless they’re willing to engage with Mistral’s sales team or use the hosted API at metered pricing.\nTo draw an analogy: Apache 2.0 is like a public library—you walk in, borrow the book, and use it however you need. Mistral’s modified MIT license is more like a corporate co-working space that’s free for freelancers but charges rent once your company hits a certain size.\nWeighing Devstral Small 2 for Enterprise Use\nThis division raises an obvious question for larger companies: can Devstral Small 2 with its more permissive and unrestricted Apache 2.0 licensing serve as a viable alternative for medium-to-large enterprises?\nThe answer depends on context. Devstral Small 2 scores 68.0% on SWE-bench, significantly ahead of many larger open models, and remains deployable on single-GPU or CPU-only setups. For teams focused on:\n\ninternal tooling,\n\non-prem deployment,\n\nlow-latency edge inference,\n…it offers a rare combination of legality, performance, and convenience.\n\nBut the performance gap from Devstral 2 is real. For multi-agent setups, deep monorepo refactoring, or long-context code analysis, that 4-point benchmark delta may understate the actual experience difference.\nFor most enterprises, Devstral Small 2 will serve either as a low-friction way to prototype—or as a pragmatic bridge until licensing for Devstral 2 becomes feasible. It is not a drop-in replacement for the flagship, but it may be “good enough” in specific production slices, particularly when paired with Vibe CLI.\nBut because Devstral Small 2 can be run entirely offline — including on a single GPU machine or a sufficiently specced laptop — it unlocks a critical use case for developers and teams operating in tightly controlled environments. \nWhether you’re a solo indie building tools on the go, or part of a company with strict data governance or compliance mandates, the ability to run a performant, long-context coding model without ever hitting the internet is a powerful differentiator. No cloud calls, no third-party telemetry, no risk of data leakage — just local inference with full visibility and control.\nThis matters in industries like finance, healthcare, defense, and advanced manufacturing, where data often cannot leave the network perimeter. But it’s just as useful for developers who prefer autonomy over vendor lock-in — or who want their tools to work the same on a plane, in the field, or inside an air-gapped lab. In a market where most top-tier code models are delivered as API-only SaaS products, Devstral Small 2 offers a rare level of portability, privacy, and ownership.\nIn that sense, Mistral isn’t just offering open models—they’re offering multiple paths to adoption, depending on your scale, compliance posture, and willingness to engage.\nIntegration, Infrastructure, and Access\nFrom a technical standpoint, Mistral’s models are built for deployment. Devstral 2 requires a minimum of 4× H100-class GPUs, and is already available on build.nvidia.com. \nDevstral Small 2 can run on a single GPU or CPU such as those in a standard laptop, making it accessible to solo developers and embedded teams alike.\nBoth models support quantized FP4 and FP8 weights, and are compatible with vLLM for scalable inference. Fine-tuning is supported out of the box.\nAPI pricing—after the free introductory window—follows a token-based structure:\n\nDevstral 2: $0.40 per million input tokens / $2.00 for output\n\nDevstral Small 2: $0.10 input / $0.30 output\n\nThat pricing sits just below OpenAI’s GPT-4 Turbo, and well below Anthropic’s Claude Sonnet at comparable performance levels.\nDeveloper Reception: Ground-Level Buzz\nOn X (formerly Twitter), developers reacted quickly with a wave of positive reception, with Hugging Face's Head of Product Victor Mustar asking if the small, Apache 2.0 licensed variant was the \"new local coding king,\" i.e., the one developers could use to run on their laptops directly and privately, without an internet connection:\n\nAnother popular AI news and rumors account, TestingCatalogNews, posted that it was \"SOTTA in coding,\" or \"State Of The Tiny Art\"\n\nAnother user, @xlr8harder, took issue with the custom licensing terms for Devstral 2, writing \"calling the Devstral 2 license 'modified MIT' is misleading at best. It’s a proprietary license with MIT-like attribution requirements.\"\n\nWhile the tone was critical, it reflected some attention Mistral’s license structuring was receiving, particularly among developers familiar with open-use norms.\nStrategic Context: From Codestral to Devstral and Mistral 3\nMistral’s steady push into software development tools didn’t start with Devstral 2—it began in May 2024 with Codestral, the company’s first code-focused large language model. A 22-billion parameter system trained on more than 80 programming languages, Codestral was designed for use in developer environments ranging from basic autocompletions to full function generation. The model launched under a non-commercial license but still outperformed heavyweight competitors like CodeLlama 70B and Deepseek Coder 33B in early benchmarks such as HumanEval and RepoBench.\nCodestral’s release marked Mistral’s first move into the competitive coding-model space, but it also established a now-familiar pattern: technically lean models with surprisingly strong results, a wide context window, and licensing choices that invited developer experimentation. Industry partners including JetBrains, LlamaIndex, and LangChain quickly began integrating the model into their workflows, citing its speed and tool compatibility as key differentiators.\nOne year later, the company followed up with Devstral, a 24B model purpose-built for “agentic” behavior—handling long-range reasoning, file navigation, and autonomous code modification. Released in partnership with All Hands AI and licensed under Apache 2.0, Devstral was notable not just for its portability (it could run on a MacBook or RTX 4090), but for its performance: it beat out several closed models on SWE-Bench Verified, a benchmark of 500 real-world GitHub issues.\nThen came Mistral 3, announced in December 2025 as a portfolio of 10 open-weight models targeting everything from drones and smartphones to cloud infrastructure. This suite included both high-end models like Mistral Large 3 (a MoE system with 41 active parameters and 256K context) and lightweight “Ministral” variants that could run on 4GB of VRAM. All were licensed under Apache 2.0, reinforcing Mistral’s commitment to flexible, edge-friendly deployment.\nMistral 3 positioned the company not as a direct competitor to frontier models like GPT-5 or Gemini 3, but as a developer-first platform for customized, localized AI systems. Co-founder Guillaume Lample described the vision as “distributed intelligence”—many smaller systems tuned for specific tasks and running outside centralized infrastructure. “In more than 90% of cases, a small model can do the job,” he told VentureBeat. “It doesn’t have to be a model with hundreds of billions of parameters.”\nThat broader strategy helps explain the significance of Devstral 2. It’s not a one-off release but a continuation of Mistral’s long-running commitment to code agents, local-first deployment, and open-weight availability—an ecosystem that began with Codestral, matured through Devstral, and scaled up with Mistral 3. Devstral 2, in this framing, is not just a model. It’s the next version of a playbook that’s been unfolding in public for over a year.\nFinal Thoughts (For Now): A Fork in the Road\nWith Devstral 2, Devstral Small 2, and Vibe CLI, Mistral AI has drawn a clear map for developers and companies alike. The tools are fast, capable, and thoughtfully integrated. But they also present a choice—not just in architecture, but in how and where you’re allowed to use them.\nIf you’re an individual developer, small startup, or open-source maintainer, this is one of the most powerful AI systems you can freely run today. \nIf you’re a Fortune 500 engineering lead, you’ll need to either talk to Mistral—or settle for the smaller model and make it work.\nIn a market increasingly dominated by black-box models and SaaS lock-ins, Mistral’s offer is still a breath of fresh air. Just read the fine print before you start building.","guid":"3RNDEkKIiY2dY6n5v4XnJF","categories":["AI"],"isoDate":"2025-12-09T19:44:00.000Z"},{"creator":"Javier Marquez","title":"La élite de los modelos abiertos hablaba en chino. Mistral acaba de situar a Europa en un nivel que ni EEUU logró alcanzar","link":"https://www.xataka.com/robotica-e-ia/elite-modelos-abiertos-hablaba-chino-mistral-acaba-situar-a-europa-nivel-que-eeuu-logro-alcanzar","pubDate":"Tue, 09 Dec 2025 19:46:13 +0100","dc:creator":"Javier Marquez","content":"\n     \n                                             <p>\n      <img src=\"https://i.blogs.es/752ff2/mistrai-ai/1024_2000.jpeg\" alt=\"La&#x20;&#x00E9;lite&#x20;de&#x20;los&#x20;modelos&#x20;abiertos&#x20;hablaba&#x20;en&#x20;chino.&#x20;Mistral&#x20;acaba&#x20;de&#x20;situar&#x20;a&#x20;Europa&#x20;en&#x20;un&#x20;nivel&#x20;que&#x20;ni&#x20;EEUU&#x20;logr&#x00F3;&#x20;alcanzar\">\n    </p>\n    <p>Durante el último año, la élite de los modelos abiertos para programación asistida, al menos en <em>benchmarks</em> como <a rel=\"noopener, noreferrer\" href=\"https://epoch.ai/benchmarks/swe-bench-verified\">SWE-Bench Verified</a>, ha hablado con acento chino. Nombres como <a class=\"text-outboundlink\" href=\"https://www.xataka.com/robotica-e-ia/he-probado-deepseek-v3-chat-deepseek-r1-razonamiento-openai-google-meta-tienen-aqui-rivales-formidables\" data-vars-post-title=\"He probado DeepSeek en la web y en mi Mac. ChatGPT, Claude y Gemini tienen un problemón\" data-vars-post-url=\"https://www.xataka.com/robotica-e-ia/he-probado-deepseek-v3-chat-deepseek-r1-razonamiento-openai-google-meta-tienen-aqui-rivales-formidables\">DeepSeek</a>, <a class=\"text-outboundlink\" href=\"https://www.xataka.com/basics/kimi-k2-thinking-que-caracteristicas-este-modelo-inteligencia-artificial-diferencias-gemini-chatgpt\" data-vars-post-title=\"Kimi K2 Thinking: qué es, características de este modelo de inteligencia artificial y diferencias con Gemini y ChatGPT\" data-vars-post-url=\"https://www.xataka.com/basics/kimi-k2-thinking-que-caracteristicas-este-modelo-inteligencia-artificial-diferencias-gemini-chatgpt\">Kimi</a> o <a class=\"text-outboundlink\" href=\"https://www.xataka.com/basics/qwen-que-como-usar-inteligencia-artificial-alibaba-gratis-tener-que-pagar-cuotas\" data-vars-post-title=\"Qwen: qué es y cómo usar la inteligencia artificial de Alibaba gratis sin tener que pagar cuotas\" data-vars-post-url=\"https://www.xataka.com/basics/qwen-que-como-usar-inteligencia-artificial-alibaba-gratis-tener-que-pagar-cuotas\">Qwen</a> se habían instalado en los puestos más altos de las pruebas y marcaban el ritmo en las tareas complejas de ingeniería de software, mientras Europa buscaba todavía su posición. La llegada de <a rel=\"noopener, noreferrer\" href=\"https://mistral.ai/news/devstral-2-vibe-cli\">Devstral 2</a> altera ese reparto. No desplaza a quienes ya estaban arriba, pero sitúa a Mistral en el mismo nivel de exigencia y convierte a una compañía europea en aspirante real en un terreno que hasta ahora parecía reservado a otros.</p>\n<!-- BREAK 1 --><p><strong>Cambio de liga: el salto técnico que llevaba tiempo gestándose</strong>. Durante los últimos meses, los modelos abiertos desarrollados en Europa y Estados Unidos habían mostrado una evolución constante, aunque aún sin el rendimiento necesario para competir en las pruebas más exigentes. El progreso era evidente, pero faltaba un proyecto capaz de consolidarlo en un nivel superior y demostrar que ese camino podía dar resultados comparables a los referentes del sector.</p>\n<p><strong>Devstral 2 en datos: rendimiento, tamaño y licencias</strong>. El nuevo modelo de Mistral alcanza los 123B parámetros en una arquitectura densa y ofrece un contexto ampliado de 256K tokens, acompañado de una licencia MIT modificada que facilita su adopción en entornos abiertos. Su versión compacta, Devstral Small 2, reduce el modelo a 24B parámetros bajo licencia <a rel=\"noopener, noreferrer\" href=\"https://www.apache.org/licenses/LICENSE-2.0\">Apache 2.0.</a> <a rel=\"noopener, noreferrer\" href=\"https://cms.mistral.ai/assets/d295e716-acbe-4d05-8764-861ca2f2a2eb.png?width=1686&height=1093\">En las cifras de SWE-Bench Verified publicadas por la compañía</a>, Devstral 2 obtiene un 72,2%, una marca que lo sitúa en el tramo más competitivo de los modelos abiertos evaluados y que confirma su presencia entre las alternativas más avanzadas del segmento.</p>\n<!-- BREAK 2 -->\r<div class=\"article-asset-image article-asset-normal article-asset-center\">\n <div class=\"asset-content\">\n                   \n   <img alt=\"Devstral Swe Bench Verified Openweights Vs Proprietary Models Dark 1\" class=\"centro_sinmarco\" src=\"https://i.blogs.es/714077/devstral---swe-bench-verified_-openweights-vs-proprietary-models-dark-1-/450_1000.png\">\n   \n      </div>\n</div>\n<p>La refleja un panorama concentrado en la parte alta del <em>benchmark</em>. Entre los modelos abiertos, <a class=\"text-outboundlink\" href=\"https://www.xataka.com/robotica-e-ia/deepseek-ha-lanzado-su-nuevo-modelo-razonador-gratis-supera-a-gpt-5\" data-vars-post-title=\"El nuevo modelo de DeepSeek razona, es gratis... y supera a GPT-5\" data-vars-post-url=\"https://www.xataka.com/robotica-e-ia/deepseek-ha-lanzado-su-nuevo-modelo-razonador-gratis-supera-a-gpt-5\">DeepSeek V3.2</a> encabeza el conjunto con un 73,1%, seguido por <a class=\"text-outboundlink\" href=\"https://www.xataka.com/basics/kimi-k2-thinking-que-caracteristicas-este-modelo-inteligencia-artificial-diferencias-gemini-chatgpt\" data-vars-post-title=\"Kimi K2 Thinking: qué es, características de este modelo de inteligencia artificial y diferencias con Gemini y ChatGPT\" data-vars-post-url=\"https://www.xataka.com/basics/kimi-k2-thinking-que-caracteristicas-este-modelo-inteligencia-artificial-diferencias-gemini-chatgpt\">Kimi K2 Thinking</a> con un 71,3% y por propuestas como Qwen 3 Coder Plus y Minimax M2, que se sitúan en el entorno de los 69 puntos. En niveles inferiores aparecen GLM 4.6, GPT-OSS-120B, CWM y DeepSWE, con resultados más moderados. En el ámbito comercial cerrado (modelos propietarios), el gráfico incorpora puntuaciones superiores: <a class=\"text-outboundlink\" href=\"https://www.xataka.com/basics/gemini-3-cuales-novedades-nuevo-modelo-inteligencia-artificial-google\" data-vars-post-title=\"Gemini 3: cuáles son las novedades del nuevo modelo de inteligencia artificial de Google \" data-vars-post-url=\"https://www.xataka.com/basics/gemini-3-cuales-novedades-nuevo-modelo-inteligencia-artificial-google\">Gemini 3 Pro</a> alcanza un 76,2%, GPT 5.1 Codex Max sube hasta el 77,9% y <a class=\"text-outboundlink\" href=\"https://www.xataka.com/robotica-e-ia/nuevo-claude-sonnet-4-5-esta-aqui-anthropic-quiere-ser-imbatible-programacion-su-ambicion-va-alla\" data-vars-post-title=\"El nuevo Claude Sonnet 4.5 ya está aquí: Anthropic quiere ser imbatible en programación, aunque su ambición va más allá\" data-vars-post-url=\"https://www.xataka.com/robotica-e-ia/nuevo-claude-sonnet-4-5-esta-aqui-anthropic-quiere-ser-imbatible-programacion-su-ambicion-va-alla\">Claude Sonnet 4.5</a> firma un 77,2%, todos ellos por encima de las mejores marcas registradas por los modelos abiertos.</p>\n<!-- BREAK 3 -->\r<p><strong>Qué mide realmente SWE-Bench Verified y por qué importa</strong>. SWE-Bench Verified es una prueba diseñada para evaluar si un modelo puede resolver tareas reales de programación, no ejercicios sintéticos. Cada caso presenta un error en un repositorio de código abierto y exige un parche que haga pasar las pruebas antes fallidas. La evaluación busca medir si el sistema entiende la estructura del proyecto, identifica la causa del problema y propone una solución coherente. Es una métrica útil y exigente, aunque limitada a repositorios en Python y a un conjunto concreto de situaciones que no cubren toda la amplitud del trabajo en software.</p>\n<!-- BREAK 4 -->\r<div class=\"article-asset-video article-asset-normal\">\n <div class=\"asset-content\">\n  <div class=\"base-asset-video\">\n   <div class=\"js-dailymotion\">\n    <script type=\"application/json\">\n                          {\"videoId\":\"x9hhg44\",\"autoplay\":false,\"title\":\"La VERDAD de la IA- Así funciona ChatGPT 4, DALL-E o MIDJOURNEY 🤖 🧠 INTELIGENCIA ARTIFICIAL\", \"tag\":\"webedia-prod\", \"duration\":\"1173\"}\n                  </script>\n   </div>\n  </div>\n </div>\n</div>\n<p><strong>De copilotos a agentes que actúan sobre el proyecto</strong>. La llegada de Devstral 2 coincide con un cambio más amplio en la forma de trabajar con herramientas de programación. Ya no se trata solo de recibir sugerencias en el editor, sino de contar con agentes capaces de explorar un repositorio completo, interpretar su estructura y proponer cambios coherentes con su estado real. En ese contexto aparece Vibe CLI, una herramienta que permite a Devstral analizar archivos, modificar partes del código y ejecutar acciones directamente desde la terminal, acercando estas capacidades al flujo de trabajo cotidiano de los desarrolladores.</p>\n<!-- BREAK 5 --><p><strong>Coste y despliegue: qué puede hacer cada tipo de usuario con Devstral</strong>. El modelo estará disponible de forma gratuita durante un periodo inicial y después pasará a costar 0,40 dólares por millón de tokens de entrada y 2,00 dólares por millón de salida, mientras que la versión Small 2 tendrá un precio inferior. Su despliegue también marca diferencias: Devstral 2 requiere al menos cuatro GPU de clase H100, orientadas a centros de datos, mientras que Devstral Small 2 está pensado para ejecutarse en una única GPU y, según la documentación de Mistral, la familia Devstral Small también puede funcionar en configuraciones solo con CPU, sin GPU dedicada. Esta variedad permite que tanto empresas como desarrolladores individuales encuentren un punto de entrada adecuado.</p>\n\r<div class=\"article-asset article-asset-normal article-asset-center\">\n <div class=\"desvio-container\">\n  <div class=\"desvio\">\n   <div class=\"desvio-figure js-desvio-figure\">\n    <a href=\"https://www.xataka.com/robotica-e-ia/hace-cuarto-siglo-estudiante-unio-32-tarjetas-graficas-geforce-para-jugar-a-quake-iii-alli-salio-cuda\" class=\"pivot-outboundlink\" data-vars-post-title=\"Hace un cuarto de siglo un estudiante unió 32 tarjetas gráficas GeForce para jugar a Quake III. De allí salió CUDA \">\n     <img alt=\"Hace&#x20;un&#x20;cuarto&#x20;de&#x20;siglo&#x20;un&#x20;estudiante&#x20;uni&#x00F3;&#x20;32&#x20;tarjetas&#x20;gr&#x00E1;ficas&#x20;GeForce&#x20;para&#x20;jugar&#x20;a&#x20;Quake&#x20;III.&#x20;De&#x20;all&#x00ED;&#x20;sali&#x00F3;&#x20;CUDA&#x20;\" width=\"375\" height=\"142\" src=\"https://i.blogs.es/0f2c1c/nvidia-quake-cuda/375_142.jpeg\">\n    </a>\n   </div>\n   <div class=\"desvio-summary\">\n    <div class=\"desvio-taxonomy js-desvio-taxonomy\">\n     <a href=\"https://www.xataka.com/robotica-e-ia/hace-cuarto-siglo-estudiante-unio-32-tarjetas-graficas-geforce-para-jugar-a-quake-iii-alli-salio-cuda\" class=\"desvio-taxonomy-anchor pivot-outboundlink\" data-vars-post-title=\"Hace un cuarto de siglo un estudiante unió 32 tarjetas gráficas GeForce para jugar a Quake III. De allí salió CUDA \">En Xataka</a>\n    </div>\n    <a href=\"https://www.xataka.com/robotica-e-ia/hace-cuarto-siglo-estudiante-unio-32-tarjetas-graficas-geforce-para-jugar-a-quake-iii-alli-salio-cuda\" class=\"desvio-title js-desvio-title pivot-outboundlink\" data-vars-post-title=\"Hace un cuarto de siglo un estudiante unió 32 tarjetas gráficas GeForce para jugar a Quake III. De allí salió CUDA \">Hace un cuarto de siglo un estudiante unió 32 tarjetas gráficas GeForce para jugar a Quake III. De allí salió CUDA </a>\n   </div>\n  </div>\n </div>\n</div>\n<p>La aparición de Devstral 2 introduce un elemento inesperado en un espacio donde las compañías chinas marcaban el paso y donde ni siquiera Estados Unidos, pese a su liderazgo en inteligencia artificial, contaba con un modelo abierto en esta franja alta de rendimiento en SWE-Bench Verified. Mistral no desplaza a quienes ya estaban arriba, pero sí amplía la conversación y demuestra que Europa puede competir en un terreno donde hasta ahora no figuraba. Es un movimiento que no altera la jerarquía general, aunque sí abre un margen nuevo para la evolución de las herramientas de programación asistida.</p>\n<!-- BREAK 6 --><p>Imágenes | Xataka con Gemini 3</p>\n<p>En Xataka | <a class=\"text-outboundlink\" href=\"https://www.xataka.com/robotica-e-ia/openai-google-niegan-que-vayan-a-meter-anuncios-chatgpt-gemini-realidad-que-cuentas-no-salen-solo-suscripciones\" data-vars-post-title=\"OpenAI y Google niegan que vayan a meter anuncios en ChatGPT y Gemini. La realidad es que las cuentas no salen sólo con suscripciones \" data-vars-post-url=\"https://www.xataka.com/robotica-e-ia/openai-google-niegan-que-vayan-a-meter-anuncios-chatgpt-gemini-realidad-que-cuentas-no-salen-solo-suscripciones\">OpenAI y Google niegan que vayan a meter anuncios en ChatGPT y Gemini. La realidad es que las cuentas no salen sólo con suscripciones</a></p>\n\r<script>\n (function() {\n  window._JS_MODULES = window._JS_MODULES || {};\n  var headElement = document.getElementsByTagName('head')[0];\n  if (_JS_MODULES.instagram) {\n   var instagramScript = document.createElement('script');\n   instagramScript.src = 'https://platform.instagram.com/en_US/embeds.js';\n   instagramScript.async = true;\n   instagramScript.defer = true;\n   headElement.appendChild(instagramScript);\n  }\n })();\n</script>\n\n\n                <p> - <br/> La noticia\n      <a href=\"https://www.xataka.com/robotica-e-ia/elite-modelos-abiertos-hablaba-chino-mistral-acaba-situar-a-europa-nivel-que-eeuu-logro-alcanzar?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=09_Dec_2025\">\n       <em> La élite de los modelos abiertos hablaba en chino. Mistral acaba de situar a Europa en un nivel que ni EEUU logró alcanzar </em>\n      </a>\n      fue publicada originalmente en\n      <a href=\"https://www.xataka.com?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=09_Dec_2025\">\n       <strong> Xataka </strong>\n      </a>\n             por <a\n        href=\"https://www.xataka.com/autor/javier-marquez?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=09_Dec_2025\">\n        Javier Marquez\n       </a>\n      . </p>\n               \n    ","contentSnippet":"Durante el último año, la élite de los modelos abiertos para programación asistida, al menos en benchmarks como SWE-Bench Verified, ha hablado con acento chino. Nombres como DeepSeek, Kimi o Qwen se habían instalado en los puestos más altos de las pruebas y marcaban el ritmo en las tareas complejas de ingeniería de software, mientras Europa buscaba todavía su posición. La llegada de Devstral 2 altera ese reparto. No desplaza a quienes ya estaban arriba, pero sitúa a Mistral en el mismo nivel de exigencia y convierte a una compañía europea en aspirante real en un terreno que hasta ahora parecía reservado a otros.\nCambio de liga: el salto técnico que llevaba tiempo gestándose. Durante los últimos meses, los modelos abiertos desarrollados en Europa y Estados Unidos habían mostrado una evolución constante, aunque aún sin el rendimiento necesario para competir en las pruebas más exigentes. El progreso era evidente, pero faltaba un proyecto capaz de consolidarlo en un nivel superior y demostrar que ese camino podía dar resultados comparables a los referentes del sector.\nDevstral 2 en datos: rendimiento, tamaño y licencias. El nuevo modelo de Mistral alcanza los 123B parámetros en una arquitectura densa y ofrece un contexto ampliado de 256K tokens, acompañado de una licencia MIT modificada que facilita su adopción en entornos abiertos. Su versión compacta, Devstral Small 2, reduce el modelo a 24B parámetros bajo licencia Apache 2.0. En las cifras de SWE-Bench Verified publicadas por la compañía, Devstral 2 obtiene un 72,2%, una marca que lo sitúa en el tramo más competitivo de los modelos abiertos evaluados y que confirma su presencia entre las alternativas más avanzadas del segmento.\n\r\n \nLa refleja un panorama concentrado en la parte alta del benchmark. Entre los modelos abiertos, DeepSeek V3.2 encabeza el conjunto con un 73,1%, seguido por Kimi K2 Thinking con un 71,3% y por propuestas como Qwen 3 Coder Plus y Minimax M2, que se sitúan en el entorno de los 69 puntos. En niveles inferiores aparecen GLM 4.6, GPT-OSS-120B, CWM y DeepSWE, con resultados más moderados. En el ámbito comercial cerrado (modelos propietarios), el gráfico incorpora puntuaciones superiores: Gemini 3 Pro alcanza un 76,2%, GPT 5.1 Codex Max sube hasta el 77,9% y Claude Sonnet 4.5 firma un 77,2%, todos ellos por encima de las mejores marcas registradas por los modelos abiertos.\n\rQué mide realmente SWE-Bench Verified y por qué importa. SWE-Bench Verified es una prueba diseñada para evaluar si un modelo puede resolver tareas reales de programación, no ejercicios sintéticos. Cada caso presenta un error en un repositorio de código abierto y exige un parche que haga pasar las pruebas antes fallidas. La evaluación busca medir si el sistema entiende la estructura del proyecto, identifica la causa del problema y propone una solución coherente. Es una métrica útil y exigente, aunque limitada a repositorios en Python y a un conjunto concreto de situaciones que no cubren toda la amplitud del trabajo en software.\n\r\n \nDe copilotos a agentes que actúan sobre el proyecto. La llegada de Devstral 2 coincide con un cambio más amplio en la forma de trabajar con herramientas de programación. Ya no se trata solo de recibir sugerencias en el editor, sino de contar con agentes capaces de explorar un repositorio completo, interpretar su estructura y proponer cambios coherentes con su estado real. En ese contexto aparece Vibe CLI, una herramienta que permite a Devstral analizar archivos, modificar partes del código y ejecutar acciones directamente desde la terminal, acercando estas capacidades al flujo de trabajo cotidiano de los desarrolladores.\nCoste y despliegue: qué puede hacer cada tipo de usuario con Devstral. El modelo estará disponible de forma gratuita durante un periodo inicial y después pasará a costar 0,40 dólares por millón de tokens de entrada y 2,00 dólares por millón de salida, mientras que la versión Small 2 tendrá un precio inferior. Su despliegue también marca diferencias: Devstral 2 requiere al menos cuatro GPU de clase H100, orientadas a centros de datos, mientras que Devstral Small 2 está pensado para ejecutarse en una única GPU y, según la documentación de Mistral, la familia Devstral Small también puede funcionar en configuraciones solo con CPU, sin GPU dedicada. Esta variedad permite que tanto empresas como desarrolladores individuales encuentren un punto de entrada adecuado.\n\r\nEn Xataka\n    \nHace un cuarto de siglo un estudiante unió 32 tarjetas gráficas GeForce para jugar a Quake III. De allí salió CUDA \n   \nLa aparición de Devstral 2 introduce un elemento inesperado en un espacio donde las compañías chinas marcaban el paso y donde ni siquiera Estados Unidos, pese a su liderazgo en inteligencia artificial, contaba con un modelo abierto en esta franja alta de rendimiento en SWE-Bench Verified. Mistral no desplaza a quienes ya estaban arriba, pero sí amplía la conversación y demuestra que Europa puede competir en un terreno donde hasta ahora no figuraba. Es un movimiento que no altera la jerarquía general, aunque sí abre un margen nuevo para la evolución de las herramientas de programación asistida.\nImágenes | Xataka con Gemini 3\nEn Xataka | OpenAI y Google niegan que vayan a meter anuncios en ChatGPT y Gemini. La realidad es que las cuentas no salen sólo con suscripciones\n\r\n (function() {\n  window._JS_MODULES = window._JS_MODULES || {};\n  var headElement = document.getElementsByTagName('head')[0];\n  if (_JS_MODULES.instagram) {\n   var instagramScript = document.createElement('script');\n   instagramScript.src = 'https://platform.instagram.com/en_US/embeds.js';\n   instagramScript.async = true;\n   instagramScript.defer = true;\n   headElement.appendChild(instagramScript);\n  }\n })();\n\n\n\n                \n - \n La noticia\n      \n        La élite de los modelos abiertos hablaba en chino. Mistral acaba de situar a Europa en un nivel que ni EEUU logró alcanzar \n      \n      fue publicada originalmente en\n      \n        Xataka \n      \n             por \n        Javier Marquez\n       \n      .","guid":"https://www.xataka.com/robotica-e-ia/elite-modelos-abiertos-hablaba-chino-mistral-acaba-situar-a-europa-nivel-que-eeuu-logro-alcanzar","isoDate":"2025-12-09T18:46:13.000Z"},{"creator":"Rubén Andrés","title":"Los espías también quieren jubilarse: el CNI se suma a la carrera para conseguir el mejor talento ","link":"https://www.xataka.com/empresas-y-economia/espias-tambien-quieren-jubilarse-cni-se-suma-a-carrera-para-conseguir-mejor-talento","pubDate":"Tue, 09 Dec 2025 19:16:13 +0100","dc:creator":"Rubén Andrés","content":"\n     \n                                             <p>\n      <img src=\"https://i.blogs.es/58750c/chris-yang-1tns_bvy9jk-unsplash/1024_2000.jpeg\" alt=\"Los&#x20;esp&#x00ED;as&#x20;tambi&#x00E9;n&#x20;quieren&#x20;jubilarse&#x3A;&#x20;el&#x20;CNI&#x20;se&#x20;suma&#x20;a&#x20;la&#x20;carrera&#x20;para&#x20;conseguir&#x20;el&#x20;mejor&#x20;talento&#x20;\">\n    </p>\n    <p>Tal vez no te habías enterado porque son muy discretos, pero <a class=\"text-outboundlink\" href=\"https://www.xataka.com/empresas-y-economia/dato-revela-complicado-futuro-relevo-laboral-espana-habra-solo-joven-cada-tres-profesionales-que-se-jubilen\" data-vars-post-title=\"España tiene un gran problema con el relevo generacional del mercado laboral: faltan 3,5 millones de trabajadores jóvenes\" data-vars-post-url=\"https://www.xataka.com/empresas-y-economia/dato-revela-complicado-futuro-relevo-laboral-espana-habra-solo-joven-cada-tres-profesionales-que-se-jubilen\">el relevo generacional</a> se ha convertido en <a class=\"text-outboundlink\" href=\"https://www.xataka.com/empresas-y-economia/espana-afrontaba-envejecimiento-dramatico-sus-funcionarios-asi-esta-logrando-corregirlo\" data-vars-post-title=\"España afrontaba un envejecimiento dramático entre sus funcionarios. Así está logrando corregirlo\" data-vars-post-url=\"https://www.xataka.com/empresas-y-economia/espana-afrontaba-envejecimiento-dramatico-sus-funcionarios-asi-esta-logrando-corregirlo\">una necesidad urgente</a> para el Centro Nacional de Inteligencia (CNI). Al igual que ocurre en buena parte de la Administración, la edad media de su plantilla aumenta de forma sostenida y obliga a incorporar perfiles jóvenes de manera constante.</p>\n<!-- BREAK 1 --><p><a rel=\"noopener, noreferrer\" href=\"https://www.papelesdelpsicologo.es/pdf/2138.pdf\">Un informe</a> de 2021 ya señalaba esa tendencia de la plantilla, que presenta al Centro de Inteligencia como una estructura cada vez más veterana y una demanda creciente de especialistas capaces de cubrir áreas estratégicas, desde la ciberseguridad hasta la operación de <a class=\"text-outboundlink\" href=\"https://www.xataka.com/energia/problemas-tension-han-vuelto-al-sistema-electrico-espanol-gran-pregunta-que-hemos-estado-haciendo-estos-ultimos-seis-meses\" data-vars-post-title=\"Un fantasma recorre España: el fantasma de otro apagón masivo provocado por los problemas de tensión en la red\" data-vars-post-url=\"https://www.xataka.com/energia/problemas-tension-han-vuelto-al-sistema-electrico-espanol-gran-pregunta-que-hemos-estado-haciendo-estos-ultimos-seis-meses\">infraestructuras sensibles</a>.</p>\n<p><strong>Mucho más que analistas y técnicos</strong>. Aunque el CNI acostumbra a asociarse a perfiles altamente cualificados en inteligencia, tecnología o lenguas, el abanico de vacantes real es más amplio y, como <a class=\"text-outboundlink\" href=\"https://www.xataka.com/empresas-y-economia/espana-va-a-necesitar-construir-viviendas-ha-chocado-muro-no-hay-profesionales-que-hagan\" data-vars-post-title=\"España va a necesitar construir más viviendas, pero ha chocado contra un muro: no hay profesionales que las hagan \" data-vars-post-url=\"https://www.xataka.com/empresas-y-economia/espana-va-a-necesitar-construir-viviendas-ha-chocado-muro-no-hay-profesionales-que-hagan\">muchas otras empresas</a>, también está notando la <a class=\"text-outboundlink\" href=\"https://www.xataka.com/empresas-y-economia/sector-construccion-ha-descubierto-algo-quieres-albaniles-hay-que-pagarles-darles-vacaciones\" data-vars-post-title=\"La construcción se ha quedado sin relevo generacional: han descubierto que nadie es albañil por vocación\" data-vars-post-url=\"https://www.xataka.com/empresas-y-economia/sector-construccion-ha-descubierto-algo-quieres-albaniles-hay-que-pagarles-darles-vacaciones\">escasez de personal</a> de mantenimiento.</p>\n<!-- BREAK 2 --><p>Tal y <a rel=\"noopener, noreferrer\" href=\"https://www.infobae.com/espana/2025/11/07/los-servicios-secretos-buscan-cerrajeros-fontaneros-economistas-y-futuros-agentes-con-titulacion-universitaria-que-toleren-la-presion/\">como recogía</a> <em>Infobae</em>, en los últimos procesos de reclutamiento, el organismo de Inteligencia ha insistido en la necesidad de oficios esenciales para el funcionamiento de sus instalaciones: cerrajeros, electricistas, fontaneros, técnicos de climatización o especialistas en mantenimiento industrial. Basta con visitar <a rel=\"noopener, noreferrer\" href=\"https://www.cni.es/selecciona-perfil\">su portal de empleo</a> para darse cuenta del número de ofertas de empleo para este tipo de profesionales.</p>\n\r<div class=\"article-asset article-asset-normal article-asset-center\">\n <div class=\"desvio-container\">\n  <div class=\"desvio\">\n   <div class=\"desvio-figure js-desvio-figure\">\n    <a href=\"https://www.xataka.com/seguridad/espana-tiene-centro-criptologico-nacional-adscrito-al-cni-visitamos-epicentro-ciberseguridad-pais\" class=\"pivot-outboundlink\" data-vars-post-title=\"Visitamos el Centro Criptológico Nacional del CNI: aquí está el epicentro de la ciberseguridad española\">\n     <img alt=\"Visitamos&#x20;el&#x20;Centro&#x20;Criptol&#x00F3;gico&#x20;Nacional&#x20;del&#x20;CNI&#x3A;&#x20;aqu&#x00ED;&#x20;est&#x00E1;&#x20;el&#x20;epicentro&#x20;de&#x20;la&#x20;ciberseguridad&#x20;espa&#x00F1;ola\" width=\"375\" height=\"142\" src=\"https://i.blogs.es/48ffce/ccn/375_142.jpeg\">\n    </a>\n   </div>\n   <div class=\"desvio-summary\">\n    <div class=\"desvio-taxonomy js-desvio-taxonomy\">\n     <a href=\"https://www.xataka.com/seguridad/espana-tiene-centro-criptologico-nacional-adscrito-al-cni-visitamos-epicentro-ciberseguridad-pais\" class=\"desvio-taxonomy-anchor pivot-outboundlink\" data-vars-post-title=\"Visitamos el Centro Criptológico Nacional del CNI: aquí está el epicentro de la ciberseguridad española\">En Xataka</a>\n    </div>\n    <a href=\"https://www.xataka.com/seguridad/espana-tiene-centro-criptologico-nacional-adscrito-al-cni-visitamos-epicentro-ciberseguridad-pais\" class=\"desvio-title js-desvio-title pivot-outboundlink\" data-vars-post-title=\"Visitamos el Centro Criptológico Nacional del CNI: aquí está el epicentro de la ciberseguridad española\">Visitamos el Centro Criptológico Nacional del CNI: aquí está el epicentro de la ciberseguridad española</a>\n   </div>\n  </div>\n </div>\n</div>\n<p><strong>El detalle: son más que fontaneros</strong>. Sin embargo, hay algo en estas ofertas que llama la atención: además de la titulación que acredita los conocimientos técnicos, se valora tener un nivel B2 de francés, alemán, italiano, portugués, ruso, árabe o chino. No es casualidad. En el CNI hasta los electricistas son agentes potenciales. \"No solo son perfiles para trabajar en las instalaciones del CNI, sino que a veces son necesarios para determinadas operaciones que llevamos a cabo\", <a rel=\"noopener, noreferrer\" href=\"https://www.infobae.com/espana/2025/11/07/los-servicios-secretos-buscan-cerrajeros-fontaneros-economistas-y-futuros-agentes-con-titulacion-universitaria-que-toleren-la-presion/\">declaraba</a> a <em>Infobae</em> un agente del CNI con 20 años de experiencia.</p>\n<!-- BREAK 3 --><p>Más allá de ese detalle, el motivo de tener su propio equipo de mantenimiento interno es sencilla: son posiciones críticas para la seguridad física de complejos donde cualquier intervención, por pequeña que sea, debe quedar bajo supervisión interna reduciendo la intervención de contratas externas.</p>\n<p><strong>El CNI te encuentra</strong>. Tal y <a rel=\"noopener, noreferrer\" href=\"https://www.elperiodico.com/es/politica/20251209/cni-busca-personal-citas-espana-124573547\">como publicaba</a> <em>El Periódico</em>, el Centro Nacional de Inteligencia se ha lanzado a la caza de talento, ganando visibilidad en <a class=\"text-outboundlink\" href=\"https://www.xataka.com/seguridad/un-ciberataque-deja-fuera-de-juego-la-intranet-de-telefonica-en-toda-espana\" data-vars-post-title=\"Un ciberataque deja fuera de juego la intranet de Telefónica en toda España\" data-vars-post-url=\"https://www.xataka.com/seguridad/un-ciberataque-deja-fuera-de-juego-la-intranet-de-telefonica-en-toda-espana\">eventos de ciberseguridad</a> y ferias de empleo. Según fuentes del CNI consultadas por el diario, gracias a esta apertura laboral ya se han llevado a cabo 4.000 entrevistas a distintos perfiles técnicos en lo que va de año.</p>\n<!-- BREAK 4 --><p>En estas entrevistas de trabajo no solo interviene el personal de Recursos Humanos del CNI, sino que en algunas de ellas también intervienen de forma discreta los jefes de sección que demandan candidatos. De ese modo, son los propios responsables del CNI quienes eligen a sus futuros miembros.</p>\n<p><strong>Los espías no son funcionarios. </strong>Los trabajadores del CNI no son funcionarios equiparables al resto de la Administración. Su estatus es el de personal estatutario del CNI, <a rel=\"noopener, noreferrer\" href=\"https://www.boe.es/buscar/act.php?id=BOE-A-2013-3907\">regido por una normativa propia</a> que determina el acceso, la movilidad interna, la evaluación y las condiciones de trabajo.</p>\n<!-- BREAK 5 --><p>Este marco responde a la naturaleza del organismo: un servicio de inteligencia en el que se trabaja con información sensible y, en ocasiones, clasificada de seguridad nacional.</p>\n<p><strong>La competencia de la empresa privada</strong>. Al contrario de lo que sucede con el <a class=\"text-outboundlink\" href=\"https://www.xataka.com/empresas-y-economia/teletrabajo-va-cediendo-cuota-frente-a-vuelta-a-oficina-hay-oasis-que-resiste-administracion-publica\" data-vars-post-title=\"Las empresas lo apostaron todo por la vuelta a la oficina. La Administración pública guarda un as en la manga: el teletrabajo\" data-vars-post-url=\"https://www.xataka.com/empresas-y-economia/teletrabajo-va-cediendo-cuota-frente-a-vuelta-a-oficina-hay-oasis-que-resiste-administracion-publica\">resto de la Administración</a>, uno de los obstáculos más complejos del relevo generacional del CNI es la competencia del sector privado. La captación de perfiles tecnológicos (ciberseguridad, análisis de datos, ingeniería de sistemas) obliga a rivalizar con empresas privadas que están ofreciendo salarios superiores, mayor flexibilidad laboral y opciones de teletrabajo.</p>\n<!-- BREAK 6 --><p>Aunque en la sección de empleo del CNI se especifica que no es obligatorio vivir en Madrid, los nuevos candidatos deben cumplir una formación previa en las instalaciones que el organismo tiene en la capital. No obstante, uno de sus mayores inconvenientes es que, aunque se desarrollen en cualquier lugar de España, muchos puestos requieren presencia física y no permiten el uso de conexiones externas. Cualquier acceso externo implica un riesgo potencial, lo que limita la adopción de modalidades híbridas. Esto choca frontalmente con la <a class=\"text-outboundlink\" href=\"https://www.xataka.com/empresas-y-economia/empresas-han-puesto-fin-al-teletrabajo-empleados-estan-moviendo-ficha-clave-flexibilidad-horario\" data-vars-post-title=\"Las empresas han puesto fin al teletrabajo, pero los empleados están moviendo ficha: la clave es la flexibilidad de horario \" data-vars-post-url=\"https://www.xataka.com/empresas-y-economia/empresas-han-puesto-fin-al-teletrabajo-empleados-estan-moviendo-ficha-clave-flexibilidad-horario\">reclamación de flexibilidad</a> de estos perfiles técnicos.</p>\n\r<div class=\"article-asset-video article-asset-normal\">\n <div class=\"asset-content\">\n  <div class=\"base-asset-video\">\n   <div class=\"js-dailymotion\">\n    <script type=\"application/json\">\n                          {\"videoId\":\"x7ztx9j\",\"autoplay\":false,\"title\":\"Ransomware qué es, cómo infecta y cómo protegerse\", \"tag\":\"ransomware\", \"duration\":\"165\"}\n                  </script>\n   </div>\n  </div>\n </div>\n</div>\n<p><strong>Una renovación inevitable.</strong> Tal y como detallan las fuentes del CNI consultadas por <em>El Periódico, </em>el reto interno del CNI para los próximos años consistirá en mantener ese flujo constante de nuevo talento mientras la generación del <em>Baby boom</em> se jubila.</p>\n<!-- BREAK 7 --><p>Moverse en un entorno donde la discreción, las restricciones operativas y la imposibilidad de dar demasiados datos sobre la naturaleza del trabajo juegan contra las necesidades de un servicio secreto. Ahora ya sabemos que, si estás interesado en trabajar para el CNI, no siempre son ellos quienes intentarán reclutarte. También puedes <a class=\"text-outboundlink\" href=\"https://www.xataka.com/basics/como-crear-mejorar-tu-curriculum-usando-inteligencia-artificial\" data-vars-post-title=\"Cómo crear y mejorar tu curriculum usando inteligencia artificial\" data-vars-post-url=\"https://www.xataka.com/basics/como-crear-mejorar-tu-curriculum-usando-inteligencia-artificial\">enviarles el currículum</a>.</p>\n<p>En Xataka | <a class=\"text-outboundlink\" href=\"https://www.xataka.com/legislacion-y-derechos/tenemos-absoluta-seguridad-que-ataque-externo-telefonos-pedro-sanchez-ministra-defensa-han-sido-infectados-pegasus-gobierno\" data-vars-post-title=\"&quot;Tenemos la absoluta seguridad de que es un ataque externo&quot;. Los teléfonos de Pedro Sánchez y la ministra de defensa han sido infectados con Pegasus, según el Gobierno\" data-vars-post-url=\"https://www.xataka.com/legislacion-y-derechos/tenemos-absoluta-seguridad-que-ataque-externo-telefonos-pedro-sanchez-ministra-defensa-han-sido-infectados-pegasus-gobierno\">\"Tenemos la absoluta seguridad de que es un ataque externo\". Los teléfonos de Pedro Sánchez y la ministra de defensa han sido infectados con Pegasus, según el Gobierno</a></p>\n<!-- BREAK 8 --><p>Imagen | Unsplash (<a rel=\"noopener, noreferrer\" href=\"https://unsplash.com/es/fotos/fotografia-de-silueta-de-hombre-1tnS_BVy9Jk\">Chris Yang</a>)</p>\n\r<script>\n (function() {\n  window._JS_MODULES = window._JS_MODULES || {};\n  var headElement = document.getElementsByTagName('head')[0];\n  if (_JS_MODULES.instagram) {\n   var instagramScript = document.createElement('script');\n   instagramScript.src = 'https://platform.instagram.com/en_US/embeds.js';\n   instagramScript.async = true;\n   instagramScript.defer = true;\n   headElement.appendChild(instagramScript);\n  }\n })();\n</script>\n\n\n                <p> - <br/> La noticia\n      <a href=\"https://www.xataka.com/empresas-y-economia/espias-tambien-quieren-jubilarse-cni-se-suma-a-carrera-para-conseguir-mejor-talento?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=09_Dec_2025\">\n       <em> Los espías también quieren jubilarse: el CNI se suma a la carrera para conseguir el mejor talento  </em>\n      </a>\n      fue publicada originalmente en\n      <a href=\"https://www.xataka.com?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=09_Dec_2025\">\n       <strong> Xataka </strong>\n      </a>\n             por <a\n        href=\"https://www.xataka.com/autor/ruben-andres?utm_source=feedburner&amp;utm_medium=feed&amp;utm_campaign=09_Dec_2025\">\n        Rubén Andrés\n       </a>\n      . </p>\n               \n    ","contentSnippet":"Tal vez no te habías enterado porque son muy discretos, pero el relevo generacional se ha convertido en una necesidad urgente para el Centro Nacional de Inteligencia (CNI). Al igual que ocurre en buena parte de la Administración, la edad media de su plantilla aumenta de forma sostenida y obliga a incorporar perfiles jóvenes de manera constante.\nUn informe de 2021 ya señalaba esa tendencia de la plantilla, que presenta al Centro de Inteligencia como una estructura cada vez más veterana y una demanda creciente de especialistas capaces de cubrir áreas estratégicas, desde la ciberseguridad hasta la operación de infraestructuras sensibles.\nMucho más que analistas y técnicos. Aunque el CNI acostumbra a asociarse a perfiles altamente cualificados en inteligencia, tecnología o lenguas, el abanico de vacantes real es más amplio y, como muchas otras empresas, también está notando la escasez de personal de mantenimiento.\nTal y como recogía Infobae, en los últimos procesos de reclutamiento, el organismo de Inteligencia ha insistido en la necesidad de oficios esenciales para el funcionamiento de sus instalaciones: cerrajeros, electricistas, fontaneros, técnicos de climatización o especialistas en mantenimiento industrial. Basta con visitar su portal de empleo para darse cuenta del número de ofertas de empleo para este tipo de profesionales.\n\r\nEn Xataka\n    \nVisitamos el Centro Criptológico Nacional del CNI: aquí está el epicentro de la ciberseguridad española\n   \nEl detalle: son más que fontaneros. Sin embargo, hay algo en estas ofertas que llama la atención: además de la titulación que acredita los conocimientos técnicos, se valora tener un nivel B2 de francés, alemán, italiano, portugués, ruso, árabe o chino. No es casualidad. En el CNI hasta los electricistas son agentes potenciales. \"No solo son perfiles para trabajar en las instalaciones del CNI, sino que a veces son necesarios para determinadas operaciones que llevamos a cabo\", declaraba a Infobae un agente del CNI con 20 años de experiencia.\nMás allá de ese detalle, el motivo de tener su propio equipo de mantenimiento interno es sencilla: son posiciones críticas para la seguridad física de complejos donde cualquier intervención, por pequeña que sea, debe quedar bajo supervisión interna reduciendo la intervención de contratas externas.\nEl CNI te encuentra. Tal y como publicaba El Periódico, el Centro Nacional de Inteligencia se ha lanzado a la caza de talento, ganando visibilidad en eventos de ciberseguridad y ferias de empleo. Según fuentes del CNI consultadas por el diario, gracias a esta apertura laboral ya se han llevado a cabo 4.000 entrevistas a distintos perfiles técnicos en lo que va de año.\nEn estas entrevistas de trabajo no solo interviene el personal de Recursos Humanos del CNI, sino que en algunas de ellas también intervienen de forma discreta los jefes de sección que demandan candidatos. De ese modo, son los propios responsables del CNI quienes eligen a sus futuros miembros.\nLos espías no son funcionarios. Los trabajadores del CNI no son funcionarios equiparables al resto de la Administración. Su estatus es el de personal estatutario del CNI, regido por una normativa propia que determina el acceso, la movilidad interna, la evaluación y las condiciones de trabajo.\nEste marco responde a la naturaleza del organismo: un servicio de inteligencia en el que se trabaja con información sensible y, en ocasiones, clasificada de seguridad nacional.\nLa competencia de la empresa privada. Al contrario de lo que sucede con el resto de la Administración, uno de los obstáculos más complejos del relevo generacional del CNI es la competencia del sector privado. La captación de perfiles tecnológicos (ciberseguridad, análisis de datos, ingeniería de sistemas) obliga a rivalizar con empresas privadas que están ofreciendo salarios superiores, mayor flexibilidad laboral y opciones de teletrabajo.\nAunque en la sección de empleo del CNI se especifica que no es obligatorio vivir en Madrid, los nuevos candidatos deben cumplir una formación previa en las instalaciones que el organismo tiene en la capital. No obstante, uno de sus mayores inconvenientes es que, aunque se desarrollen en cualquier lugar de España, muchos puestos requieren presencia física y no permiten el uso de conexiones externas. Cualquier acceso externo implica un riesgo potencial, lo que limita la adopción de modalidades híbridas. Esto choca frontalmente con la reclamación de flexibilidad de estos perfiles técnicos.\n\r\nUna renovación inevitable. Tal y como detallan las fuentes del CNI consultadas por El Periódico, el reto interno del CNI para los próximos años consistirá en mantener ese flujo constante de nuevo talento mientras la generación del Baby boom se jubila.\nMoverse en un entorno donde la discreción, las restricciones operativas y la imposibilidad de dar demasiados datos sobre la naturaleza del trabajo juegan contra las necesidades de un servicio secreto. Ahora ya sabemos que, si estás interesado en trabajar para el CNI, no siempre son ellos quienes intentarán reclutarte. También puedes enviarles el currículum.\nEn Xataka | \"Tenemos la absoluta seguridad de que es un ataque externo\". Los teléfonos de Pedro Sánchez y la ministra de defensa han sido infectados con Pegasus, según el Gobierno\nImagen | Unsplash (Chris Yang)\n\r\n (function() {\n  window._JS_MODULES = window._JS_MODULES || {};\n  var headElement = document.getElementsByTagName('head')[0];\n  if (_JS_MODULES.instagram) {\n   var instagramScript = document.createElement('script');\n   instagramScript.src = 'https://platform.instagram.com/en_US/embeds.js';\n   instagramScript.async = true;\n   instagramScript.defer = true;\n   headElement.appendChild(instagramScript);\n  }\n })();\n\n\n\n                \n - \n La noticia\n      \n        Los espías también quieren jubilarse: el CNI se suma a la carrera para conseguir el mejor talento  \n      \n      fue publicada originalmente en\n      \n        Xataka \n      \n             por \n        Rubén Andrés\n       \n      .","guid":"https://www.xataka.com/empresas-y-economia/espias-tambien-quieren-jubilarse-cni-se-suma-a-carrera-para-conseguir-mejor-talento","isoDate":"2025-12-09T18:16:13.000Z"}]